namespace SkeleTest { ///
/// Interaction logic for MainWindow.xaml ///
public partial class MainWindow : Window { public MainWindow() { InitailizeComponent(); }

    ///Enables sensor and skeletons for tracking (max of 6)
    KinectSensor sensor;
    const int SKELETON_COUNT = 6;
    Skeleton[] allSkeletons = new Skeleton[SKELETON_COUNT];

    private void Window_Loaded(object sender, RoutedEventArgs e)
    {
        ///Enables the first kinect sensor it finds
        if(KinectSensor.KinectSensors.Count > 0)
        {
            sensor = KinectSensor.KinectSensors[0];
        }
        
        ///If sensor is enabled, than it turns on different funcitons
        if(sensor.Status == KinectStatus.Connected)
        {
            ///Picks up camera color, depth perception, and skeleton tracking
            sensor.ColorStream.Enable();
            sensor.DepthStream.Enable();
            sensor.SkeletonStream.Enable();

           ///More enabling and camera functions
            sensor.DepthStream.Range = DepthRange.Near;
            sensor.SkeletonStream.EnableTrackingInNearRange = true;
            sensor.SkeletonStream.TrackingMode = SkeletonTrackingMode.Seated;

            ///?????
            sensor.AllFramesReady += new EventHandler<AllFramesReadyEventArgs>(sensor_AllFramesReady);
            sensor.Start();
        }
    }

    void sensor_AllFramesReady(object sender, AllFramesReadyEventArgs e)
    {
        using(ColorImageFrame colorFrame = e.OpenColorImageFrame())
        {
            ///If the camera is broken it boots out
            if(colorFrame == null)
            {
                return;
            }

            ///Makes the pixels for the screen
            byte[] pixels = new byte[colorFrame.PixelDataLength];
            colorFrame.CopyPixelDataTo(pixels);

            ///Something for the video stream. Makes it 32FpS
            int stride = colorFrame.Width * 4;
            vid.Source = BitmapSource.Create(colorFrame.Width, colorFrame.Height, 96, 96, PixelFormats.Bgr32, null, pixels, stride);
        }

        ///???
        Skeleton me = null;
        GetSkeleton(e, ref me);

        ///Ensures there is at least one skeleton
        if(me == null)
        {
            return;
        }

        GetCameraPoint(me, e);
    }

    private void GetSkeleton(AllFramesReadyEventArgs e, ref Skeleton me)
    {
        using(SkeletonFrame skeletonFrameData = e.OpenSkeletonFrame())
        {
            ///???
            if(skeletonFrameData == null)
            {
                return;
            }

            ///???
            skeletonFrameData.CopySkeletonDataTo(allSkeletons);
            me = (from s in allSkeletons where s.TrackingState == SkeletonTrackingState.Tracked select s).FirstorDefault();
        }
    }

    private void GetCameraPoint(Skeleton me, AllFramesReadyEventArgs e)
    {
        using(DepthImageFrame depth = e.OpenDepthImageFrame())
        {
            ///Makes sure that the camera is working or it will boot out
            if(depth == null || sensor == null)
            {
                return;
            }

            ///Used for the head tracking 
            DepthImagePoint headDepthPoint = depth.MapFromSkeletonPoint(me.Joints[JointType.Head].Position);
            ColorImagePoint headColorPoint = depth.MapToColorImagePoint(headDepthPoint.X, headDepthPoint.Y, ColorImageFormat.RgbResolution640x480Fps30);

            ///Used to place an image over the head position
            Canvas.SetLeft(face, headColorPoint.X - face.Width / 2);
            Canvas.SetTop(face, headColorPoint.Y - face.Height / 2);
        }
    }

    private void Window_Closing(object sender, System.ComponentModel.CancelEventArgs e)
    {
        sensor.Stop();
    }
}
